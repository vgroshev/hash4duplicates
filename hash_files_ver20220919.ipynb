{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\">__Сентябрь '2022__</font>\n",
    "\n",
    "__Сводный блокнот__, объединяющий оба этапа:\n",
    "\n",
    "- Сбор информации (имя, размер в байтах, расширение, хэш) по файлам из заданной папки;\n",
    "- Отбор только уникальных в новую папку с сохранением исходной иерархической структуры вложенных папок.\n",
    "\n",
    "10.01.2022:\n",
    "- добавлено время создания, последнего доступа и изменения\n",
    "\n",
    "19.04.2022\n",
    "-  добавлена возможность обработки длинных имен файлов (с помощью **UNC**), переменная *unc_prefix*\n",
    "\n",
    "19.09.2022\n",
    "- учтена обработка UNC в функции по копированию уникальных; удалена зависимость от библиотеки *tqdm*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I Подготовительная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# built-in libraries, не нужно устанавливать дополнительно\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import hashlib\n",
    "import shutil\n",
    "import platform\n",
    "\n",
    "from time import localtime, strftime\n",
    "from datetime import datetime\n",
    "from pathlib import PurePath\n",
    "\n",
    "# external libraries, сторонние библиотеки, требуется установка\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(f'Доступные алгоритмы хэширования:\\n {hashlib.algorithms_guaranteed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Питон здесь:', sys.executable)\n",
    "print('Версия:', platform.python_version())  # Версия: 3.6.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка версий установленных библиотек\n",
    "lib_list = [pd, np]\n",
    "\n",
    "from importlib_metadata import version\n",
    "for p in lib_list:\n",
    "    print(f'{p.__name__:12} {version(p.__name__)}')\n",
    "\n",
    "# проверено для:\n",
    "# pandas       1.1.5\n",
    "# numpy        1.19.0\n",
    "# но может хватить и более ранних версий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Определение функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNC-префикс, чтобы избежать проблемы длинных имен\n",
    "unc_prefix = \"\\\\\\\\?\\\\\"\n",
    "\n",
    "def calc_hash(file, block_size=2**18):\n",
    "    \"\"\"\n",
    "    Вычисление хэша для файла.\n",
    "    Размер блока для обработки задан параметром block_size.\n",
    "    Тип алгоритма хэширования (sha256) задан внутри.\n",
    "    \"\"\"\n",
    "    file_hash = hashlib.sha256() # = Создаем объект с помощью выбранного алгоритма хэширования\n",
    "    with open(file, 'rb') as f: # Open the file to read it's bytes\n",
    "        fb = f.read(block_size) # Read from the file. Take in the amount declared above\n",
    "        while len(fb) > 0: # While there is still data being read from the file\n",
    "            file_hash.update(fb) # Update the hash\n",
    "            fb = f.read(block_size) # Read the next block from the file\n",
    "    return (file_hash.hexdigest()) # Get the hexadecimal digest of the hash\n",
    "\n",
    "def collect_stat(fld_in):\n",
    "    \"\"\"\n",
    "    Собираем статистику о файлах, обходя папку, полученную на вход -- fld_in.\n",
    "    10.01.22 - добавил время (создания, последнего доступа, изменения)\n",
    "    \"\"\"\n",
    "    def strftime_loc(timestamp):\n",
    "        try:\n",
    "            return strftime(\"%Y-%m-%d %H:%M:%S\", timestamp)\n",
    "        except:\n",
    "            return \"\"\n",
    "    \n",
    "    \n",
    "    time_started = datetime.now()\n",
    "    print('Начало работы - ', time_started)\n",
    "    for root, folders, files in os.walk(fld_in):\n",
    "        for f in files:\n",
    "            full_path = unc_prefix + os.path.join(root, f)\n",
    "            # если файл не является ссылкой\n",
    "            if not os.path.islink(full_path):\n",
    "                file_size = os.path.getsize(full_path)\n",
    "                file_ctime = localtime(os.path.getctime(full_path)) # created at\n",
    "                file_atime = localtime(os.path.getatime(full_path)) # accessed \n",
    "                file_mtime = localtime(os.path.getmtime(full_path)) # modified\n",
    "                fhash = calc_hash(full_path)\n",
    "            else: # если все же ссылка, то оставляем пустыми\n",
    "                file_size = None\n",
    "                file_ctime = None # created at\n",
    "                file_atime = None # accessed \n",
    "                file_mtime = None # modified\n",
    "                fhash = None\n",
    "            # расширение можно извлекать в любом случае (и ссылка, и не ссылка)\n",
    "            ftype = os.path.splitext(full_path)[1][1:]\n",
    "            msg = \"; \".join(list(map(str, [root, full_path, ftype, file_size, fhash])) + \n",
    "                            list(map(strftime_loc, [file_ctime, file_atime, file_mtime]))\n",
    "                           )\n",
    "            log_hashfiles.info(msg)\n",
    "    print('Завершено - ', datetime.now())\n",
    "    print(f'Затрачено времени: {datetime.now() - time_started}')\n",
    "    \n",
    "def delete_empty_folders(folder_out):\n",
    "    \"\"\"Walk all subfolders of folder_out and\n",
    "    delete empty (not containing neither files nor folders)\"\"\"\n",
    "    q_deleted = 0\n",
    "    for item in os.walk(folder_out):\n",
    "        # берем список подпапок текущей папки\n",
    "        for subdir in item[1]:\n",
    "            path_to_subdir = os.path.join(item[0], subdir)\n",
    "            # если она пустая, то удаляем\n",
    "            if not os.listdir(path_to_subdir):\n",
    "                print(path_to_subdir)\n",
    "                os.rmdir(path_to_subdir)\n",
    "                q_deleted += 1\n",
    "    print('Done. Deleted empty folders:', q_deleted)\n",
    "    return q_deleted\n",
    "\n",
    "\n",
    "def csv_to_datafr_proc(file_in):\n",
    "    \"\"\"\n",
    "    Читаем путь к csv, обрабатываем,\n",
    "    возвращаем датафрейм, обогащенный\n",
    "    10.01.2022 -- добавлены три столбца в заголовок также.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_in,\n",
    "                     sep=';',\n",
    "                     encoding='utf8',\n",
    "                     header=None,\n",
    "                     names=['Folder', 'Full_path', 'Type', 'Size_bytes', 'Hash', 'ctime', 'atime', 'mtime'])\n",
    "    try:\n",
    "        df.Folder = df.Folder.apply(lambda x: str(x)[10:]) # Убираем первые символы \n",
    "        df.Type = df.Type.apply(lambda x: str(x).lower())  # Приводим все расширения файлов к нижнему регистру\n",
    "        df['Drive'] = df.Folder.apply(lambda x: PurePath(str(x)).parts[3] if len(PurePath(str(x)).parts)>3 else \"-\")\n",
    "        df['File'] = df.Full_path.apply(lambda x: os.path.basename(str(x)))\n",
    "        df['dir'] = df['Full_path'].apply(lambda x: os.path.dirname(str(x)).split('/')[-1])\n",
    "        df['key_fn_hash'] = df['File'].astype('str') + '_' + df['Hash'] # Ключ из двух полей: имя файла_хэш\n",
    "        df['MegaBytes'] = np.round(df['Size_bytes'] / 1048576, 1)  # Размер файла в Мб, округленный до десятых\n",
    "    except:\n",
    "        pass\n",
    "        print('error')\n",
    "    print('df.shape:', df.shape)\n",
    "    return df\n",
    "          \n",
    "##################################################################          \n",
    "# Вспомогательные функции для создания логгера и его сворачивания.\n",
    "##################################################################\n",
    "          \n",
    "def init_logging(log_name, filename, level):\n",
    "    \"\"\"\n",
    "    Создаем логгер для записи событий.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(log_name)\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    _log_format = f'%(asctime)s: [%(levelname)s]: %(message)s'\n",
    "    _date_format = '%Y-%m-%d %H:%M:%S'\n",
    "    file_handler = logging.FileHandler(filename, mode='w', encoding='utf8')\n",
    "    file_handler.setLevel(level)\n",
    "    file_handler.setFormatter(logging.Formatter(_log_format, _date_format))\n",
    "    logger.addHandler(file_handler)\n",
    "    return logger\n",
    "\n",
    "def remove_handlers(some_logger):\n",
    "    \"\"\"\n",
    "    Удаляем все хэндлеры из логгера\n",
    "    \"\"\"\n",
    "    for hndl in some_logger.handlers:\n",
    "        hndl.close()\n",
    "        some_logger.removeHandler(hndl)\n",
    "\n",
    "        \n",
    "########################################################################          \n",
    "# Функции для 2 части: копирования уникальных по ключу (имя_хэш) файлов\n",
    "########################################################################\n",
    "\n",
    "def get_dest_name(source_f, dest_f, full_filename):\n",
    "    \"\"\"\n",
    "    В папке source_f находится структура, которую нужно\n",
    "    сохранить при копировании в папку dest_f.\n",
    "    Работаем с полным путем к одному из файлов -- full_filename.\n",
    "    ---\n",
    "    Возвращаем новое полное имя в целевой папке с учетом вложенности\n",
    "    исходного пути.\n",
    "    Возвращаем None, если переданы несовпадающие логические пути источника\n",
    "    и находящегося в нем файла.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        path_sf = PurePath(source_f)\n",
    "        path_file = PurePath(full_filename)\n",
    "        second_part = path_file.relative_to(path_sf)\n",
    "    except:\n",
    "        # Например, если путь к файлу не дочерний по отношению к папке-источнику\n",
    "        return None\n",
    "\n",
    "    return PurePath(dest_f).joinpath(second_part)\n",
    "\n",
    "\n",
    "def create_dir(dir_name):\n",
    "    \"\"\"Создаем папку, если она не существует (и все подпапки на пути к конечной также)\n",
    "    В случае ошибки, ничего не делаем.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(dir_name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def copy_selected_files(folder_in, check_list, folder_result):\n",
    "    \"\"\"Копируем данные из папки folder_in,\n",
    "    если файл из списка check_list.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # проходим по всем подпапкам исходной папки, переданной на вход,\n",
    "        # и в зависимости от полного пути копируем в целевую или пропускаем\n",
    "        stdt = datetime.now()\n",
    "        print('Время начала:', stdt)\n",
    "        files_copied = 0\n",
    "        for fp_elem in os.walk(unc_prefix + folder_in):\n",
    "            for f in fp_elem[2]:\n",
    "                # формируем полные пути и с ними работаем\n",
    "                f_name = os.path.join(fp_elem[0], f)\n",
    "                if f_name in check_list:\n",
    "                    f_name_dest = get_dest_name(unc_prefix + folder_in,\n",
    "                                                unc_prefix + folder_result,\n",
    "                                                f_name)\n",
    "                    # create directory sub-folder before copying\n",
    "                    create_dir(os.path.dirname(f_name_dest))\n",
    "                    shutil.copy2(f_name, f_name_dest)\n",
    "                    files_copied += 1\n",
    "        # замеряем выполнение\n",
    "        enddt = datetime.now()\n",
    "        print('Время завершения:', enddt)\n",
    "        print('Затрачено, h:mm:ss:', enddt - stdt)\n",
    "        print(f'Скопировано файлов: {files_copied}')\n",
    "    except Exception as exc_err:\n",
    "        err_msg = 'Ошибка. Данные не скопированы.'\n",
    "        print(err_msg)\n",
    "        print(exc_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II Основная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Задаем параметры -- имена папок и файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Полный путь к папке, которую анализируем\n",
    "folder_in = r'C:\\Users\\user\\Documents\\20220919_УдалениеДубликатов_Хэш (исправления)\\out'\n",
    "\n",
    "# Для сохранения результатов:\n",
    "fname = '2022sep19_global'\n",
    "# Имя текстового файла-лога со статистикой, из которого будет сделан датафрейм\n",
    "log_name = f'{fname}.txt'\n",
    "# Имя Excel-файла для сохранения промежуточных результатов (с уникальным ключом ИмяФайла_Хэш)\n",
    "excel_res_file = f'{fname}.xlsx'\n",
    "# Путь к папке, куда будут сохраняться отобранные уникальные\n",
    "f_out = r'C:\\Users\\user\\Documents\\20220919_УдалениеДубликатов_Хэш (исправления)\\uniq'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Сбор информации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Инициируем логгер\n",
    "log_hashfiles = init_logging('log_hashfiles',\n",
    "                           log_name,\n",
    "                           logging.INFO)\n",
    "\n",
    "# Запускаем основную функцию\n",
    "collect_stat(folder_in)\n",
    "\n",
    "# Завершаем логгирование\n",
    "remove_handlers(log_hashfiles)\n",
    "logging.shutdown()\n",
    "\n",
    "# для примерно 311 Мб\n",
    "# Начало работы -  2022-04-06 18:06:25.992508\n",
    "# Завершено -  2022-04-06 18:13:59.576907\n",
    "# Затрачено времени: 0:07:33.584399\n",
    "# Wall time: 7min 33s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Загружаем в датафрейм, сохраняем в Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "datafr = csv_to_datafr_proc(log_name)\n",
    "datafr.to_excel(excel_res_file, index=False)\n",
    "\n",
    "datafr.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Отбираем только уникальные и копируем их в новое место"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нашли всего уникальных\n",
    "datafr['key_fn_hash'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Составляем таблицу только с уникальными, отобранными по комбинации \"Имя файла - Хэш\" и встреченными первыми при обходе каталога\n",
    "df_unique_key = datafr.drop_duplicates(subset=['key_fn_hash'], keep='first')\n",
    "print(df_unique_key.shape)\n",
    "df_unique_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Составляем список имен файлов, которые будем переносить в новую папку\n",
    "files_to_copy = df_unique_key['Full_path'].apply(lambda x: x.strip()).tolist()\n",
    "print(f'Считано в список имен файлов: {len(files_to_copy)}')\n",
    "print(f'Первые 10 значений:\\n')\n",
    "files_to_copy[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# копируем в соответствии с полученным списком и полученными ранее данными\n",
    "copy_selected_files(folder_in, files_to_copy, f_out)\n",
    "\n",
    "# Пример замера скорости работы\n",
    "# Время начала: 2022-04-06 18:26:45.999040\n",
    "# Время завершения: 2022-04-06 18:28:44.798380\n",
    "# Затрачено, h:mm:ss: 0:01:58.799340\n",
    "# Скопировано файлов: 11508\n",
    "# Wall time: 1min 58s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Дополнительно:  удаление пустых вложенных папок (если они встречались) в папке-результате*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 1\n",
    "while q>0:\n",
    "    q = delete_empty_folders(f_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
